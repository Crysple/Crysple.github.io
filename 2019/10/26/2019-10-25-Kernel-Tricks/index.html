<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta property='og:image' content="/img/ogimage.jpeg">
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/img/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/avatar.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/avatar.jpeg">
  <link rel="mask-icon" href="/img/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideRightIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Part of the reason why ML algorithms can be so versatile is perhaps the use of Kernelization.  The following shows how to apply kernelization in ridge regression and shows how it can be incorparated i">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Kernel-Tricks">
<meta property="og:url" content="http://yoursite.com/2019/10/26/2019-10-25-Kernel-Tricks/index.html">
<meta property="og:site_name" content="Zejun Lin&#39;s Blog">
<meta property="og:description" content="Part of the reason why ML algorithms can be so versatile is perhaps the use of Kernelization.  The following shows how to apply kernelization in ridge regression and shows how it can be incorparated i">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-10-28T01:28:50.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kernel-Tricks">
<meta name="twitter:description" content="Part of the reason why ML algorithms can be so versatile is perhaps the use of Kernelization.  The following shows how to apply kernelization in ridge regression and shows how it can be incorparated i">

<link rel="canonical" href="http://yoursite.com/2019/10/26/2019-10-25-Kernel-Tricks/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Kernel-Tricks | Zejun Lin's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zejun Lin's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">异国漂泊，野蛮生长</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/26/2019-10-25-Kernel-Tricks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpeg">
      <meta itemprop="name" content="Daniel">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zejun Lin's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kernel-Tricks
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-26 19:37:00" itemprop="dateCreated datePublished" datetime="2019-10-26T19:37:00-04:00">2019-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-27 21:28:50" itemprop="dateModified" datetime="2019-10-27T21:28:50-04:00">2019-10-27</time>
              </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Part of the reason why ML algorithms can be so versatile is perhaps the use of <strong>Kernelization</strong>. </p>
<p>The following shows how to apply kernelization in ridge regression and shows how it can be incorparated in other algorithms.</p>
<a id="more"></a>
<h2 id="1-The-Overall-Idea"><a href="#1-The-Overall-Idea" class="headerlink" title="1. The Overall Idea"></a>1. The Overall Idea</h2><h3 id="A-Feature-expansion"><a href="#A-Feature-expansion" class="headerlink" title="A. Feature expansion"></a>A. Feature expansion</h3><h4 id="i-What-it-is"><a href="#i-What-it-is" class="headerlink" title="i). What it is"></a>i). What it is</h4><p>Feature expansion is such a <strong>transformation</strong> that maps a original data point (usually expressed as a vector) to another point in another space (another vector).Perhaps an example will make this idea clearly. The following lists two basic feature expansions when there’s only two features $(x_1, x_2)$ in a data point.</p>
<ul>
<li>Affine expansion $\phi(x) = \phi((x_1, x_2)) \rightarrow (1, x_1, x_2)$</li>
<li>Quadratic expansion $\phi(x) = \phi((x_1, x_2)) \rightarrow (1, x_1, x_2, x_1^2, x_2^2, x_1, x_2)$</li>
</ul>
<h4 id="ii-Problem-feature-dimension-explosion"><a href="#ii-Problem-feature-dimension-explosion" class="headerlink" title="ii). Problem: feature dimension explosion"></a>ii). Problem: feature dimension explosion</h4><p>However, if there are a lot of features in a data point, then the dimension of the expanded features vector will become very large. If we generalize the above quadratic expansion to n features, it becomes:</p>
<script type="math/tex; mode=display">\phi(x) = \phi((x_1, x_2, ..., x_n)) \rightarrow (1, x_1, ..., x_n, x_1^2, ..., x_n^2, x_1x_2,...,x_1x_n,...x_{n-1}x_{n})</script><p>This feature expansion has $1+2n+C_n^2 = \Theta(n^2)$ terms!!! This is really a <strong>feature dimension explosion</strong>. Take MNIST as an example, which has over 700 features. So if we apply quadratic expansion to it, the number of features will become asympotatically $700^2 = 490000$, which is teribble for computing.</p>
<h4 id="iii-Solution"><a href="#iii-Solution" class="headerlink" title="iii). Solution"></a>iii). Solution</h4><p>Fortunately, there is a trick here. If we <strong>just want to compute the inner product of two transformed vectors</strong>, then things become much easier. Take the quadratic expansion for example. We could prove that</p>
<script type="math/tex; mode=display">\phi(x)^T\phi(x') = (1+x^Tx')^2</script><p>where x and x’ are two data points.</p>
<p>In this way, we could use the original data points to compute the inner product of two transformed vectors without actually transforming them.</p>
<p>So the problem becomes how can we just utilize the inner product of two data points to perform regression model.</p>
<h3 id="B-Kernel-Function"><a href="#B-Kernel-Function" class="headerlink" title="B. Kernel Function"></a>B. Kernel Function</h3><p>Kernel function denotes an inner product in feature space and is usually denoted as:</p>
<script type="math/tex; mode=display">K(x, x') = \phi(x)^T\phi(x') = <\phi(x), \phi(x')></script><p>Using the Kernel function, we could know the inner product of two data points, <strong>without explicitly using $\phi$  to map them into a higher-dimension space</strong>. This is highly desirable, as sometimes our higher-dimensional feature space ($\phi$’s output space) could even be infinite-dimensional and thus unfeasible to compute.</p>
<h3 id="i-How-to-take-advantage-of-this"><a href="#i-How-to-take-advantage-of-this" class="headerlink" title="i). How to take advantage of this"></a>i). How to take advantage of this</h3><p>But how can we apply this into our ML algorithms such as ridge regression without explicit mapping data points into the output space of $\phi$ ?</p>
<h2 id="2-From-Ridge-Regression"><a href="#2-From-Ridge-Regression" class="headerlink" title="2. From Ridge Regression"></a>2. From Ridge Regression</h2><blockquote>
<p>The following vectors are all considered as column vectors.</p>
</blockquote>
<h3 id="A-Primary-Form-of-Ridge-Regression"><a href="#A-Primary-Form-of-Ridge-Regression" class="headerlink" title="A. Primary Form of Ridge Regression"></a>A. Primary Form of Ridge Regression</h3><p>We know that by applying normal function, the solution to the ridge regression is usually presented in the following form:</p>
<script type="math/tex; mode=display">\hat w = (A^T A + \lambda I)^{-1}A^Ty</script><p>where $A = (\phi(x_1)|\phi(x_2)|…|\phi(x_n))^T \in R^{n\times d}$ is the data matrix after feature expansion, I is identity matrix, w is the weight we want to learn and $y = (y_1, y_2, …, y_n)$ is the true value.</p>
<p>This is called the primary form of Ridge Regression. However, if we wanna apply feature expansion in this, we have to compute $A$ or at least $AA^T$. But we do not want to explicitly apply $\phi$ to the data points. Notice that if we could somehow twist the term $A^T A$ a little bit, say, to $AA^T$, then things become much easier because $(A^TA)_{i, j} = \phi(x_i)^T\phi(x_j) = K(x_i, x_j)$, where $x_i, x_j$ is two data points.</p>
<h3 id="B-Dual-Form-of-Ridge-Regression"><a href="#B-Dual-Form-of-Ridge-Regression" class="headerlink" title="B. Dual Form of Ridge Regression"></a>B. Dual Form of Ridge Regression</h3><h4 id="i-Definition"><a href="#i-Definition" class="headerlink" title="i). Definition"></a>i). Definition</h4><blockquote>
<p>We slightly change the definition of A and y for computing convenience.</p>
<p>Now:</p>
<script type="math/tex; mode=display">A = \frac{1}{\sqrt{n}}(\phi(x_1)|\phi(x_2)|...|\phi(x_n))^T \in R^{n\times d}</script><script type="math/tex; mode=display">y = \frac{1}{\sqrt{n}}(y_1, y_2, ..., y_n)\in R^{n}</script></blockquote>
<p>Thanks to mathematicians, there is sth called linear algebraic identity, which tell us that:</p>
<script type="math/tex; mode=display">(A A^T + \lambda I)^{-1}A^T = A^T(A A^T + \lambda I)^{-1}</script><p>which can be easily proved if you expand each side</p>
<p>So we have</p>
<script type="math/tex; mode=display">\hat w= (A^T A + \lambda I)^{-1}A^Ty=A^T(A A^T + \lambda I)^{-1}y</script><p>Denote $\hat \alpha = \frac{1}{\sqrt{n}}(A A^T + \lambda I)^{-1}y$  and $K = AA^T$.</p>
<p>Here K is called  the <strong>Gram Matrix</strong>, which is just the kernel function described in the previous section where $K_{i,j} = \phi(x_i)^T\phi(x_j)$. So we know that until now, we could <em>compute $\alpha$ without doing actual feature expansion</em>.</p>
<p>But there is still a $A^T$ in the formula. Does it means we still need to use the $\phi$ function to do features expansion??? The answer is no. We could eliminate that term with the new coming points into a value that can be calculate by the kernel function.</p>
<h4 id="ii-Prediction"><a href="#ii-Prediction" class="headerlink" title="ii). Prediction"></a>ii). Prediction</h4><p>By the definition above, weight vector becomes:</p>
<script type="math/tex; mode=display">\hat w = A^T(A A^T + \lambda I)^{-1}y = \sqrt{n}A^T\hat \alpha = \sum_{i=1}^n \hat \alpha_i \phi(x_i)</script><p>When there comes a new point x, we just need to predict by:</p>
<script type="math/tex; mode=display">\phi(x^T)\hat w = \sum_{i=1}^n \hat \alpha_i \phi(x^T) \phi(x_i) = \sum_{i=1}^n \hat \alpha_i K(x^T, x_i)</script><p>Now we successfully apply kernel function in the ridge regression.</p>
<h2 id="3-Conclusion"><a href="#3-Conclusion" class="headerlink" title="3. Conclusion"></a>3. Conclusion</h2><p>The Kernel trick is a very interesting and powerful tool. It is powerful because it provides a bridge from linearity to non-linearity to any algorithm that can expressed solely on terms of <a href="http://en.wikipedia.org/wiki/Dot_product" target="_blank" rel="noopener">dot products</a> between two vectors. It comes from the fact that, if we first map our input data into a higher-dimensional space, a linear algorithm operating in this space will behave non-linearly in the original input space.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/12/25/Prediction_Theory_Basis_1/" rel="prev" title="Basics of Prediction Theory 1（预测理论基础一）">
      <i class="fa fa-chevron-left"></i> Basics of Prediction Theory 1（预测理论基础一）
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/06/10/2018-06-10/" rel="next" title="Hadoop HA搭建集群">
      Hadoop HA搭建集群 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-The-Overall-Idea"><span class="nav-number">1.</span> <span class="nav-text">1. The Overall Idea</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Feature-expansion"><span class="nav-number">1.1.</span> <span class="nav-text">A. Feature expansion</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#i-What-it-is"><span class="nav-number">1.1.1.</span> <span class="nav-text">i). What it is</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ii-Problem-feature-dimension-explosion"><span class="nav-number">1.1.2.</span> <span class="nav-text">ii). Problem: feature dimension explosion</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#iii-Solution"><span class="nav-number">1.1.3.</span> <span class="nav-text">iii). Solution</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-Kernel-Function"><span class="nav-number">1.2.</span> <span class="nav-text">B. Kernel Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#i-How-to-take-advantage-of-this"><span class="nav-number">1.3.</span> <span class="nav-text">i). How to take advantage of this</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-From-Ridge-Regression"><span class="nav-number">2.</span> <span class="nav-text">2. From Ridge Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Primary-Form-of-Ridge-Regression"><span class="nav-number">2.1.</span> <span class="nav-text">A. Primary Form of Ridge Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-Dual-Form-of-Ridge-Regression"><span class="nav-number">2.2.</span> <span class="nav-text">B. Dual Form of Ridge Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#i-Definition"><span class="nav-number">2.2.1.</span> <span class="nav-text">i). Definition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ii-Prediction"><span class="nav-number">2.2.2.</span> <span class="nav-text">ii). Prediction</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Conclusion"><span class="nav-number">3.</span> <span class="nav-text">3. Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Daniel"
      src="/img/avatar.jpeg">
  <p class="site-author-name" itemprop="name">Daniel</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Crysple" title="GitHub → https://github.com/Crysple" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:gdzejlin@gmail.com" title="E-Mail → mailto:gdzejlin@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-Danny"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Daniel</span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
